---
title: "Practical Machine Learning Course Project"
output: html_document
---
#Practical Machine Learning Course Project

##Overview
Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. Subjects were asked to perform barbell lifts correctly and incorrectly in 5 different ways. More information is available from the website here: http://groupware.les.inf.puc-rio.br/harIn. The goal of this project will be to develop a model that will accuarately predict if a person falls into one of the 5 categories.  
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

##Exploratory Analysis

```{r packages, message = FALSE}
library(caret)
library(randomForest)
library(gbm)
```

Download data
```{r data}

train.data<- read.csv(url("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"), header = TRUE)

test.data<- read.csv(url("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"), header = TRUE)


```

Cleaned data by removing variables that consisted mainly of NA values, had near zero variance, and non-relevant variables such as names and timestamps.
```{r}
## removing variables that are mostly NA
var.NA<- sapply(train.data, function(x) mean(is.na(x)))>  0.95

train.data<- train.data[ , var.NA == F]

## removing variables with Near Zero Variance

NZV<- nearZeroVar(train.data)

train.data<- train.data[ , -NZV]

## removing variables that are just for identification or timestamps

train.data<- train.data[, -(1:5)]

```

Partitioned the training data into a train and test subset for machine learning.
```{r partitioning}
set.seed(430)
Partition<- createDataPartition(train.data$classe, p = 0.7, list = FALSE)
training.set<- train.data[Partition, ]
testing.set<- train.data[-Partition, ]

```
## Prediction Models

Used a 3 fold cross-validation to optimize tuning paramters for models.

```{r cross validaton}
## Cross validation
set.seed(430)
cross.val<- trainControl(method = "cv", number= 3, verboseIter = FALSE)
```

### Recursive Partitioning Model
Has a poor accuarcy of 49.6%, so it is not a good prediction model.
```{r rpart}
set.seed(430)

model.fit.rpart<- train(classe ~., data= training.set, method ="rpart", trControl = cross.val)

predict.test.rpart<- predict(model.fit.rpart, newdata= testing.set)

confusionMatrix(testing.set$classe, predict.test.rpart)
```

### Generalized Boosted Model

Has an accuracy of 98.4%, so it could be used as a model, but there is a good likelihood of misidentification.
```{r gbm, echo = TRUE, results='hide'}
model.fit.gbm<- train(classe ~., data= training.set, method ="gbm", trControl = cross.val)
predict.test.gbm<- predict(model.fit.gbm, newdata= testing.set)
```
```{r gbm results}
confusionMatrix(testing.set$classe, predict.test.gbm)
```
## Random Forest Model

Has an accuracy of 99.8%. Because of this accuracy this is the model that will be used to compare to the testing data.
```{r random forest, cache= TRUE}
set.seed(430)
model.fit.rf<- train(classe ~., data= training.set, method ="rf", trControl = cross.val)

predict.test.rf<- predict(model.fit.rf, newdata= testing.set)

confusionMatrix(testing.set$classe, predict.test.rf)
```

## Prediction

We fit our testing data to the random forest prediction model that we used above and found the predicted "classe" for 20 points to be
```{r Predict}
#Predict Test

predict.test<- predict(model.fit.rf, newdata = test.data)

matrix(predict.test)

```

